{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "from IPython.display import display, SVG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esempio su dato sintetico\n",
    "\n",
    "Contesto: \n",
    "* [Ulam](https://en.wikipedia.org/wiki/Stanislaw_Ulam) e [Von Neumann](https://en.wikipedia.org/wiki/John_von_Neumann) si sfidano a freccette üéØ\n",
    "* Von Neumann deve ancora riprendersi dalla sbornia della sera prima üç∫\n",
    "\n",
    "Vogliamo allenare un modello:\n",
    "* che impari a riconoscere i tiri effettuati da Von Neumann\n",
    "* note le coordinate del punto in cui arriva la freccetta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(n_samples: int = 500):\n",
    "    mean1 = (0, 0)\n",
    "    cov1 = [(1, 0), (0, 1)]\n",
    "    g1 = pd.DataFrame(np.random.multivariate_normal(mean1, cov1, n_samples), columns=['x1', 'x2'])\n",
    "    g1['player'] = 'Von Neumann'\n",
    "\n",
    "    mean2 = (0, 0)\n",
    "    cov2 = [(0.25, 0), (0, 0.25)]\n",
    "    g2 = pd.DataFrame(np.random.multivariate_normal(mean2, cov2, n_samples), columns=['x1', 'x2'])\n",
    "    g2['player'] = 'Ulam'\n",
    "\n",
    "    df = pd.concat([g1, g2])\n",
    "\n",
    "    df['filter'] = np.where((df['player'] == 'Von Neumann') & (df['x1']**2 + df['x2']**2  <= np.random.uniform(1, 1.5, len(df))**2), 1, 0)\n",
    "    df.drop(df[df['filter']==1].index, inplace=True)\n",
    "    df.drop('filter', axis=1, inplace=True)\n",
    "    return shuffle(df).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = make_dataset()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizziamo il dataset tramite [seaborn](https://seaborn.pydata.org/), un'altra comoda library di data-visualization basata su matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "sns.scatterplot(\n",
    "    data=df, \n",
    "    x='x1', \n",
    "    y='x2', \n",
    "    hue='player', \n",
    "    style='player', \n",
    "    markers={'Von Neumann': 'o', 'Ulam': 's'},\n",
    "    palette={'Von Neumann': 'darkorange', 'Ulam': 'dodgerblue'}, \n",
    "    ax=ax)\n",
    "ax.set_xlim((-4, 4))\n",
    "ax.set_ylim((-4, 4));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target feature\n",
    "\n",
    "Dato che il modello deve imparare a riconoscere i tiri di Von Neumann, una scelta naturale √®:\n",
    "* assegnare il valore 1 (classe positiva) ai tiri di Von Neumann\n",
    "* assegnare il valore 0 (classe negativa) ai tiri di Ulam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-05T08:13:20.544960Z",
     "iopub.status.busy": "2021-05-05T08:13:20.544960Z",
     "iopub.status.idle": "2021-05-05T08:13:20.549950Z",
     "shell.execute_reply": "2021-05-05T08:13:20.548955Z",
     "shell.execute_reply.started": "2021-05-05T08:13:20.544960Z"
    }
   },
   "source": [
    "### Esercizio\n",
    "Crea una colonna `'true_class'` nel dataframe che abbia 1 in corrispondenza dei tiri di Von Neumann e 0 in corrispondenza di quelli di Ulam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup modello\n",
    "\n",
    "Utilizziamo un Decision Tree (algoritmo introdotto nella lezione precedente sulla regressione).\n",
    "\n",
    "> **N.B.**: gli alberi decisionali _non_ sono gli unici algoritmi in grado di risolvere task di classificazione.<br>\n",
    "Per un esempio \"visivo\" delle alternative disponibili in scikit-learn, approfondire [qui](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html#sphx-glr-auto-examples-classification-plot-classifier-comparison-py).\n",
    "\n",
    "Per comodit√†, abbiamo pronta una funzione per visualizzare le classificazioni del modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classification(df):\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(21, 6))\n",
    "    for _ax in ax:\n",
    "        _ax.set_xlim((-4, 4))\n",
    "        _ax.set_ylim((-4, 4))    \n",
    "    sns.scatterplot(data=df, x='x1', y='x2', hue='true_class', palette={0: 'dodgerblue', 1: 'darkorange'}, style='true_class', markers={1: 'o', 0: 's'}, ax=ax[0])\n",
    "    ax[0].set_title('True class')\n",
    "    sns.scatterplot(data=df, x='x1', y='x2', hue='pred_class', palette={0: 'dodgerblue', 1: 'darkorange'}, style='pred_class', markers={1: 'o', 0: 's'}, ax=ax[1])\n",
    "    ax[1].set_title('Predicted class')\n",
    "    sns.scatterplot(data=df[~df['match']], x='x1', y='x2', color='red', style='match', markers={False: 'x'}, ax=ax[2])\n",
    "    ax[2].set_title('Wrong prediction')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-05T08:17:44.337494Z",
     "iopub.status.busy": "2021-05-05T08:17:44.336458Z",
     "iopub.status.idle": "2021-05-05T08:17:44.344457Z",
     "shell.execute_reply": "2021-05-05T08:17:44.343462Z",
     "shell.execute_reply.started": "2021-05-05T08:17:44.337494Z"
    }
   },
   "source": [
    "### Esercizio\n",
    "\n",
    "1. Allena su tutto il dataset a disposizione un `DecisionTreeClassifier` che abbia:\n",
    "    * hyperparameters di default\n",
    "    * le coordinate come predittori\n",
    "    * la classe come target feature\n",
    "\n",
    "    \n",
    "2. Salva il risultato della classificazione su tutto il dataset in una nuova colonna del dataset `'pred_class'`\n",
    "\n",
    "3. Utilizza `np.where()` per controllare dove la classificazione coincide con la target feature, e salva il risultato in una nuova colonna del dataset `'match'` \n",
    "\n",
    "4. Visualizza il risultato tramite eseguendo la funzione `plot_classification(df)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizziamo l'albero (gi√† salvato tramite il seguente codice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-05T11:09:58.914697Z",
     "iopub.status.busy": "2021-05-05T11:09:58.914697Z",
     "iopub.status.idle": "2021-05-05T11:10:08.185544Z",
     "shell.execute_reply": "2021-05-05T11:10:08.184702Z",
     "shell.execute_reply.started": "2021-05-05T11:09:58.914697Z"
    }
   },
   "source": [
    "```python\n",
    "from dtreeviz.trees import dtreeviz\n",
    "\n",
    "viz = dtreeviz(\n",
    "    model, \n",
    "    df[['x1', 'x2']], \n",
    "    df['true_class'],\n",
    "    target_name='true_class',\n",
    "    feature_names=['x1', 'x2'],\n",
    "    class_names=[\"Ulam\", \"Von Neumann\"],\n",
    "    colors={'classes': [None, None, ['dodgerblue', 'darkorange']]}\n",
    ")\n",
    "\n",
    "viz.save(\"decision_tree_classifier_complete.svg\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(SVG('./decision_tree_classifier_complete.svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-05T08:34:48.554321Z",
     "iopub.status.busy": "2021-05-05T08:34:48.553287Z",
     "iopub.status.idle": "2021-05-05T08:34:48.561289Z",
     "shell.execute_reply": "2021-05-05T08:34:48.559290Z",
     "shell.execute_reply.started": "2021-05-05T08:34:48.554321Z"
    }
   },
   "source": [
    "### Esercizio\n",
    "\n",
    "Cosa noti circa il modello ottenuto?\n",
    "\n",
    "Ricicla il codice dell'esercizio precedente per ripetere l'esperimento modificando il parametro `max_depth` e visualizzando nuovamente il risultato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(SVG('./decision_tree_classifier_3depth.svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-05T08:47:47.364144Z",
     "iopub.status.busy": "2021-05-05T08:47:47.364144Z",
     "iopub.status.idle": "2021-05-05T08:47:47.371142Z",
     "shell.execute_reply": "2021-05-05T08:47:47.369144Z",
     "shell.execute_reply.started": "2021-05-05T08:47:47.364144Z"
    }
   },
   "source": [
    "### Domanda\n",
    "La visualizzazione precedente mostra gli errori di classificazione del modello. \n",
    "\n",
    "* Siamo soddisfatti di _come_ li mostra? \n",
    "* L'informazione √® sufficiente a capire se il modello ha imparato a riconoscere i tiri di Von Neumann?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-05T09:08:40.598844Z",
     "iopub.status.busy": "2021-05-05T09:08:40.598844Z",
     "iopub.status.idle": "2021-05-05T09:08:40.607481Z",
     "shell.execute_reply": "2021-05-05T09:08:40.605476Z",
     "shell.execute_reply.started": "2021-05-05T09:08:40.598844Z"
    }
   },
   "source": [
    "### Esercizio\n",
    "\n",
    "Ricava dal dataset precedente:\n",
    "\n",
    "* il numero di tiri di Von Neumann correttamente classificati\n",
    "* il numero di tiri di Ulam correttamente classificati\n",
    "* il numero di tiri di Ulam erroneamente classificati\n",
    "* il numero di tiri di Von Neumann erroneamente classificati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esercizio\n",
    "\n",
    "Le metriche calcolate nel precedente esercizio sono rispettivamente\n",
    "\n",
    "* true positives (TP) \n",
    "* true negatives (TN) \n",
    "* false positives (FP)\n",
    "* false negatives (FN) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><img src=\"./classification.png\" style=\"width:35%\"><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importa da `sklearn.metrics` la metrica `confusion_matrix` e\n",
    "\n",
    "1. valuta la metrica sul dataset\n",
    "2. verifica che il risultato coincida con quello calcolato manualmente nell'esercizio precedente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E' possibile anche visualizzare in maniera pi√π significativa la matrice di confusione tramite la funzione `plot_confusion_matrix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(\n",
    "    model, \n",
    "    df[['x1', 'x2']], \n",
    "    df['true_class'],\n",
    "    cmap='Greys',\n",
    "    labels=[0, 1],\n",
    "    display_labels=['Ulam', 'Von Neumann']\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esercizio\n",
    "\n",
    "La funzione `plot_confusion_matrix` ha un keyword argument molto utile: `normalize`, che pu√≤ assumere valore `'true'`, `'pred'` oppure `'all'`.\n",
    "\n",
    "Fai qualche esperimento normalizzando la matrice di confusione: come cambia la lettura dei risultati?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esistono [_molte_ metriche](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics) di valutazione per modelli di classificazione, ma molte di queste possono essere ricavate in maniera semplice dalla matrice di confusione. \n",
    "\n",
    "Tra loro citiamo:\n",
    "\n",
    "* **accuracy** ‚ûú $\\large \\frac{TP + TN}{TP + TN + FP + FN}$\n",
    "> quanti tiri sono stati classificati correttamente rispetto al totale?\n",
    "\n",
    "* **precision (P)** ‚ûú $\\large \\frac{TP}{TP + FP}$\n",
    "> quanti tiri sono stati classificati correttamente \"di Von Neumann\" rispetto al totale di tiri _classificati_ \"di Von Neumann\"?\n",
    "\n",
    "* **recall (R)** ‚ûú $\\large \\frac{TP}{TP + FN}$\n",
    "> quanti tiri sono stati classificati correttamente \"di Von Neumann\" rispetto al totale di tiri _effettivamente_ \"di Von Neumann\"?<br>\n",
    "nel contesto dei [_test statistici_](https://en.wikipedia.org/wiki/Sensitivity_and_specificity) conosciuta anche come **sensitivity**\n",
    "\n",
    "* **specificity** ‚ûú $\\large \\frac{TN}{TN + FP}$\n",
    "> quanti tiri sono stati classificati correttamente \"di Ulam\" rispetto al totale di tiri _effettivamente_ \"di Ulam\"?<br>\n",
    "\n",
    "- **f1-score**, [harmonic mean](https://en.wikipedia.org/wiki/Harmonic_mean#Harmonic_mean_of_two_numbers) di precision e recall ‚ûú $2\\cdot \\large \\frac{PR}{P + R}$\n",
    "\n",
    "Ogni metrica pu√≤ essere utile in determinati contesti a seconda di quale errore tra FP e FN √® pi√π interessante misurare.\n",
    "\n",
    "#### Approfondimento\n",
    "\n",
    "* un'utile visualizzazione della differenza tra precision e recall √® disponibile [qui](https://en.wikipedia.org/wiki/Precision_and_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-05T10:28:13.320230Z",
     "iopub.status.busy": "2021-05-05T10:28:13.320230Z",
     "iopub.status.idle": "2021-05-05T10:28:13.327816Z",
     "shell.execute_reply": "2021-05-05T10:28:13.326816Z",
     "shell.execute_reply.started": "2021-05-05T10:28:13.320230Z"
    }
   },
   "source": [
    "### Esercizio\n",
    "Importa da `sklearn.metrics` la metriche `accuracy_score`, `precision_score` e `recall_score`.\n",
    "\n",
    "Fai qualche esperimento per controllare che i risultati siano coerenti con quelli riportati nella matrice di confusione (ev. normalizzata).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esercizio (BONUS)\n",
    "\n",
    "Importa da `sklearn.metrics` la metrica `classification_report` e printa il risultato delle principali metriche.\n",
    "\n",
    "‚ö†Ô∏è sklearn calcola tutte le metriche precedenti _assumendo il punto di vista di ogni classe_ (es. recall e specificity sono visualizzate sotto l'unico nome \"recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approfondimento (BONUS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La classificazione binaria si pu√≤ generalizzare in\n",
    "\n",
    "* **multiclass classification** ‚ûú task in cui sono presenti $C$ classi con $C>2$ ed ogni sample pu√≤ appartenere ad una e una sola classe\n",
    "* **multilabel classification** ‚ûú task in cui vanno assegnate $M$ label binarie ad ogni sample con $M\\in [0, N]$ dove $N$ √® il numero di classi\n",
    "> le $M$ label possono essere pensate come possibili propriet√† (presenti/non presenti) di ciascun sample tra loro mutuamente non esclusive<br>\n",
    "pu√≤ essere affrontato tramite l'implementazione di $N$ classificatori binari, ciascuno per una label\n",
    "* **multiclass-multioutput classification** ‚ûú task in cui ogni sample pu√≤ ricevere $M$ label, ciascuna delle quali pu√≤ assumere $C_i>2\\;\\forall i=1,\\dots,M$ valori\n",
    "> risulta quindi una generalizzazione sia del caso _multilabel_ (perch√® considera label non binarie) sia del caso _multiclass_ (perch√® consider√† pi√π di una classe)\n",
    "\n",
    "Per approndire, [qui](https://scikit-learn.org/stable/modules/multiclass.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approfondimento (BONUS)\n",
    "\n",
    "* [soft vs hard classifiers](https://scikit-learn.org/stable/modules/ensemble.html#voting-classifier)\n",
    "* [probability calibration](https://scikit-learn.org/stable/modules/calibration.html)\n",
    "- [ROC curve](https://scikit-learn.org/stable/modules/model_evaluation.html#roc-metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-mimocko",
   "language": "python",
   "name": ".venv-mimocko"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
