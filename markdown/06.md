## Lezione #6

_29/04/2021_

Introduzione al Machine Learning (ML)

<small>üö∏ quanto segugue fa <b>largo</b> uso di semplificazioni e abusi di notazione</small>

--
#### definizione per tutti

<blockquote>
a set of methods that can automatically <span style="color:#FF7F50">detect patterns</span> in data, and then
use the uncovered patterns to <span style="color:gold">predict</span> future data, or to perform other kinds of
<span style="color:gold">decision making</span>
</blockquote>

<small>[Kevin P. Murphy, 2012]<small>

--
#### definizione per pochi

<blockquote>
a program <span style="color:#FF7F50">learns</span> from experience <span style="color:#FF7F50">$X$</span> with respect to some task $t$ and some performance
measure $L$, if $L(t)$ <span style="color:gold">improves</span> with <span style="color:gold">$X$</span>
</blockquote>

<small>[Tom Mitchell, 1997]<small>

--

Ma cosa significa <span style="color:#FF7F50">**imparare**</span> dai dati?

---
#### Un po' di nomenclatura

##### _Dati_

 <div class="twocolumn">
    <div>
    <ul>
        <li>Organizzati in matrici $X$ di dimensione $n \times d$</li>
        <li>$n \rightarrow$ esempi (<em>i.e. samples, data point, ...</em>)</li>
        <li>$d \rightarrow$ predittori (<em>i.e. features</em>)</li>
    </ul>
    </div>
    <div>
        <img src="./assets/06/data.png" height="400"/>
    </div>
</div>

--

Ogni _esempio_ √® un <span style="color:dodgerblue"><b>vettore</b></span> $\mathbf{x}_i \in \mathbb{R}^d$

<img src="./assets/06/sample.png" height="150"/>

--
#####  _Problemi non supervisionati_<sup>‚ôô</sup>

- Assenza di altre info
- Esempi:
    - Segmentazione customer base in base agli acquisti $\rightarrow$ <span style="color:crimson"><b>clustering</b></span>
    - Rappresentazione compatta scenari multidimensionali $\rightarrow$ <span style="color:darkcyan"><b>dimensionality reduction</b></span>

<small>‚ôô<em>Unsupervised Machine Learning (focus Lezione 8)</em></small>

--
#####  _Problemi supervisionati_<sup>‚ôï</sup>

- Presenza di una variabile <span style="color:GreenYellow">target $y$</span>
- I valori assunti da <span style="color:GreenYellow">$y$</span> possono essere:
    - continui, <span style="color:GreenYellow">$y_i$</span> $\in \mathbb{R} \rightarrow$ regressione<sup>‚ôò</sup>
    - binari, <span style="color:GreenYellow">$y_i$</span> $\in \\{+1, -1\\} \rightarrow$ classificazione binaria<sup>‚ôî</sup>
    - multipli, <span style="color:GreenYellow">$y_i$</span> $\in \{0, 1, \dots, k\} \rightarrow$ classificazione multi-classe<sup>‚ôó</sup>

<small>
    <ul class="no-bullets">
        <li>‚ôï <em>Supervised Machine Learning</em></li>
        <li>‚ôò <em>Regression (focus di questa lezione)</em></li>
        <li>‚ôî <em>Binary classification (focus della Lezione 7)</em></li>
        <li>‚ôó <em>Multiclass classification (focus della Lezione 7)</em></li>
    </ul>
</small>
---

Ma quindi, cosa significa <span style="color:#FF7F50">**imparare**</span> dai dati?

--
#####  _Problemi supervisionati_

Trovare <span style="color:dodgerblue">$f(\mathbb{x})$</span> che approssimi _bene_ <span style="color:GreenYellow">$y$</span>

$$\text{argmin}_{f\in\mathcal{F}}\frac{1}{n}L(f(\mathbb{x}_i), y_i)$$

<ul>
    <li>$n \rightarrow$ numero di esempi nel dataset
    <li><span style="color:dodgerblue">$f~$</span>$\rightarrow$ modello, predice il <span style="color:GreenYellow">target</span></li>
    <li><span style="color:Gold">$L~$</span>$\rightarrow$ <em>loss function</em>, misura bont√† predizione</li>
</ul>

---
##### Regression 101



---

#### Perch√® ne parliamo?

--

#### Quando dobbiamo usarlo?

--

#### Quali ostacoli troveremo?

- Pochi esempi
- Feature non rappresentative
- Preparazione del dataset
- <span style="color:Coral"><b>Underfitting</b></span> _vs_ <span style="color:FireBrick"><b>Overfitting</b></span> ‚ö†Ô∏è

<small>üêç <em>Focus</em> `Jupyter`</small>
--

<img src="./assets/06/jupyter_logo.png" height="400"/>
